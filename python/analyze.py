import json
import sys
import pandas as pd
from openai import OpenAI
from dotenv import load_dotenv
import os

load_dotenv()

api_key_value = "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"

client = OpenAI(
    base_url="https://openrouter.ai/api/v1",
    api_key=api_key_value,
)

def evaluate_response(student_code, bot_response, question_details, student_question, delimiter="###"):
    """
    AI-driven evaluation system that assesses the bot's response.
    """
    system_message = f"""You are an AI Response Analyzer focused on programming education. Your mission is to strictly assess a bot's response for accuracy, correctness, and relevance."""

    prompt = f"""
    1. Thoroughly analyze the student's code to accurately identify the issue they are facing, based on the details provided in {student_question} and {student_code}. \
    2. Understand the context of the question by identifying the key concepts being used, as outlined in {question_details}. \
    3. Analyze the code in the bot's response and evaluate the mistake it explains, as provided in {bot_response}. \
    {delimiter}
    4. If the bot response meets any of the following criteria:

        1. **Out-of-scope concepts used**:
          - The response includes constructs not mentioned in the question. For example, if the question involves lists, the bot should not use tuples, dictionaries, sets, or advanced functions like `map()`, `enumerate()`, or exception handling unless explicitly stated.
          - Tag: **[Out-of-scope concept used: <concept_name>]**

        2. **Advanced concepts used unnecessarily**:
          - The response includes advanced topics that are beyond the scope of the question, such as DSA concepts (sorting, searching, linked lists, trees, graphs, etc.), `collections` module utilities (`deque`, `Counter`, `defaultdict`, etc.), or functional programming constructs (`lambda`, `filter()`, `reduce()`).
          - These concepts should only be used if explicitly mentioned or required for the correct solution.
          - Tag: **[Unnecessary advanced concept used: <concept_name>]**

        3. **Incorrect explanation or misinterpretation of the question**:
          - The response misinterprets the student's issue, provides an incomplete explanation, or fails to address the actual mistake.
          - Examples include explaining a different error than the one present or omitting the proper fix while identifying the mistake correctly.
          - Tag: **[Incorrect explanation : <specify_reason>]**

        4. **Incorrect code that does not achieve the expected outcome**:
          - The response provides a solution that is logically or syntactically incorrect, does not meet the question's requirements, or does not solve the problem as intended.
          - <Test bot's response code and code in question details with sample inputs including worst-case scenarios>The bot's response code does not match the outputs generated by the code provided in the question details.
          - Examples include incorrect logic, missing required operations, or improper condition handling.
          - Tag: **[Incorrect solution: <mistake_description>]**

        5. **Completely irrelevant response or off-topic code**:
          - The response is entirely off-topic, providing an unrelated solution or explanation.
          - This includes responses that do not address the question at all, provide generic answers unrelated to coding, or contain significant deviations from the required solution.
          - Tag: **[Irrelevant response]**


      Else (if the bot response meets the following criteria):

        1. **Correct and relevant response provided**:
          - The response correctly identifies the mistake and provides an accurate, relevant fix that aligns with the question's requirements and constraints.
          - It strictly adheres to the given topic, avoiding unnecessary imports, unrelated concepts, or advanced constructs (e.g., `deque`, `map()`, `enumerate()`) unless explicitly mentioned.
          - The explanation remains focused, avoiding additional details or logic beyond the question's scope.
          - Tag: **[Correct and relevant response]**

    Use the following format:
      Remarks :{delimiter} <Tag>

    Make sure to must and should include {delimiter} in response remarks.
    """

    response = client.chat.completions.create(
        model="deepseek/deepseek-r1-distill-llama-70b:free",
        messages=[{'role':'system', 'content': system_message},
            {"role": "user", "content": prompt}],
        temperature = 0.2,
    )

    return response.choices[0].message.content.split("###")[-1].strip()

def process_csv(file_path):
    """
    Process the CSV file and evaluate each row
    """
    try:
        # Read CSV file
        df = pd.read_csv(file_path)
        required_columns = ['Question Details', 'Student Question', 'Student Code', 'Bot Response']
        
        # Validate columns
        if not all(col in df.columns for col in required_columns):
            raise ValueError("CSV file missing required columns")

        # Process each row
        results = []
        for index, row in df.iterrows():
            try:
                evaluation_result = evaluate_response(
                    student_code=row['Student Code'],
                    bot_response=row['Bot Response'],
                    question_details=row['Question Details'],
                    student_question=row['Student Question']
                )
                
                results.append({
                    'status': 'success',
                    'evaluation': evaluation_result.split("###")[-1].strip(),
                    'original_data': row.to_dict()
                })
            except Exception as e:
                results.append({
                    'status': 'error',
                    'message': str(e),
                    'original_data': row.to_dict()
                })

        return results

    except Exception as e:
        return [{'status': 'error', 'message': f'File processing error: {str(e)}'}]

if __name__ == "__main__":
    if len(sys.argv) != 2:
        print(json.dumps({'error': 'No file path provided'}))
        sys.exit(1)

    file_path = sys.argv[1]
    results = process_csv(file_path)
    print(json.dumps(results))
